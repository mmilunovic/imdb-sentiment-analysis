# -*- coding: utf-8 -*-
"""3a.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KNGLku41Ld2KTXcVZOgRB6GA-Zr37mF-
"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import LinearSegmentedColormap


# %matplotlib inline

class KNN:
  
  def __init__(self, nb_features, nb_classes, data, k):
    self.nb_features = nb_features
    self.nb_classes = nb_classes
    self.data = data
    self.k = k
    
    # Gradimo model, X je matrica podataka a Q je vektor koji predstavlja upit.
    self.X = tf.placeholder(shape=(None, nb_features), dtype=tf.float32)
    self.Y = tf.placeholder(shape=(None), dtype=tf.int32)
    self.Q = tf.placeholder(shape=(nb_features), dtype=tf.float32)
    
    # Racunamo kvadriranu euklidsku udaljenost i uzimamo minimalnih k.
    dists = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(self.X, self.Q)), axis=1))
    _, idxs = tf.nn.top_k(-dists, self.k)  
    
    self.classes = tf.gather(self.Y, idxs)
    self.dists = tf.gather(dists, idxs)
    
    self.w = tf.fill([k], 1/k)
    
    # Svaki red mnozimo svojim glasom i sabiramo glasove po kolonama.
    w_col = tf.reshape(self.w, (k, 1))
    self.classes_one_hot = tf.one_hot(self.classes, nb_classes)
    self.scores = tf.reduce_sum(w_col * self.classes_one_hot, axis=0)
    
    # Klasa sa najvise glasova je hipoteza.
    self.hyp = tf.argmax(self.scores)
    
    # Crtamo podatke.
    idxs0 = data['y'] == '0'
    idxs1 = data['y'] == '1'
    idxs2 = data['y'] == '2'

    plt.scatter(data['x'][idxs0, 0], data['x'][idxs0, 1], c='b', 
              edgecolors='k', label='Iris-setosa')
    plt.scatter(data['x'][idxs1, 0], data['x'][idxs1, 1], c='g', 
              edgecolors='k', label='Iris-versicolor')
    plt.scatter(data['x'][idxs2, 0], data['x'][idxs2, 1], c='r', 
              edgecolors='k', label='Iris-virginica')
    '''
    step_size = 0.01
    x1, x2 = np.meshgrid(np.arange(min(data['x'][:, 0]), max(data['x'][:, 0]), 
                               step_size),
                     np.arange(min(data['x'][:, 1]), max(data['x'][:, 1]), 
                               step_size))
    x_feed = np.vstack((x1.flatten(), x2.flatten())).T

    pred_plot = pred_list.reshape([x1.shape[0], x1.shape[1]])
    classes_cmap = LinearSegmentedColormap.from_list('classes_cmap', 
                                                 ['lightblue', 
                                                  'lightgreen', 
                                                  'lightyellow'])
    plt.contourf(x1, x2, pred_plot, cmap=classes_cmap, alpha=0.7)
    '''
  # Ako imamo odgovore za upit racunamo i accuracy.
  def predict(self, query_data):
    
    with tf.Session() as sess:
      sess.run(tf.global_variables_initializer())
     
      nb_queries = 30
      
      matches = 0
      for i in range(nb_queries):
        hyp_val = sess.run(self.hyp, feed_dict = {self.X: self.data['x'], 
                                                  self.Y: self.data['y'], 
                                                 self.Q: query_data['x'][i]})
        if query_data['y'] is not None:
          actual = query_data['y'][i]
          match = (int(hyp_val) == int(actual))
          if match:
            matches += 1
            
          if i % 10 == 0:
            print('Test example: {}/{}| Predicted: {}| Actual: {}| Match: {}'
                 .format(i, nb_queries, hyp_val, actual, match))
          
      accuracy = matches / nb_queries
      print('{} matches out of {} examples'.format(matches, nb_queries))
      
      return accuracy
    

# Ucitavamo Iris data set.
filename = 'iris.csv'
data = dict()
# Uzimamo u obzir samo prva 2 featura
data['x'] = np.loadtxt(filename, delimiter=',', skiprows=1, usecols=(0, 1))
data['y'] = np.loadtxt(filename, dtype=str, delimiter=',', skiprows=1, usecols=4)

# Mešamo podatke jer su na početku poređani po klasama
nb_samples = data['x'].shape[0]
indices = np.random.permutation(nb_samples)
data['x'] = data['x'][indices]
data['y'] = data['y'][indices]

i = 0
for x in data['y']:
  if x == 'Iris-setosa':
    data['y'][i]= 0
  elif x == 'Iris-versicolor':
    data['y'][i]= 1
  else:
    data['y'][i]= 2
  i += 1

# Delimo podatke na train i test 
split_point = int(nb_samples*0.8)

train_x = data['x'][:split_point]
train_y = data['y'][:split_point]

test_x = data['x'][split_point:]
test_y = data['y'][split_point:]

nb_train = len(train_y)
nb_test = len(test_y)

train_x = np.reshape(train_x, [nb_train, -1])
test_x = np.reshape(test_x, [nb_test, -1])

# Pokrecemo kNN na train skupu
nb_features = 2
nb_classes = 3
k = 3
train_data = {'x': train_x, 'y': train_y}
knn = KNN(nb_features, nb_classes, train_data, k)

# Pokrecemo kNN na test skupu
accuracy = knn.predict({'x': test_x, 'y': test_y})
print('Test set accuracy: ', accuracy)